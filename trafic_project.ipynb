

import pandas as pd
import numpy as np
import seaborn as sns
import sklearn as sk
from sklearn import linear_model
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline

from sklearn import tree
from sklearn import ensemble
from sklearn import svm
from xgboost import XGBRegressor
import xgboost
     

data=pd.read_csv(r"/content/traffic volume.csv")
     

data.head()
     
holiday	temp	rain	snow	weather	date	Time	traffic_volume
0	NaN	288.28	0.0	0.0	Clouds	02-10-2012	09:00:00	5545
1	NaN	289.36	0.0	0.0	Clouds	02-10-2012	10:00:00	4516
2	NaN	289.58	0.0	0.0	Clouds	02-10-2012	11:00:00	4767
3	NaN	290.13	0.0	0.0	Clouds	02-10-2012	12:00:00	5026
4	NaN	291.14	0.0	0.0	Clouds	02-10-2012	13:00:00	4918

data.describe()
     
temp	rain	snow	traffic_volume
count	48151.000000	48202.000000	48192.000000	48204.000000
mean	281.205351	0.334278	0.000222	3259.818355
std	13.343675	44.790062	0.008169	1986.860670
min	0.000000	0.000000	0.000000	0.000000
25%	272.160000	0.000000	0.000000	1193.000000
50%	282.460000	0.000000	0.000000	3380.000000
75%	291.810000	0.000000	0.000000	4933.000000
max	310.070000	9831.300000	0.510000	7280.000000

data.info()
     
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 48204 entries, 0 to 48203
Data columns (total 8 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   holiday         61 non-null     object 
 1   temp            48151 non-null  float64
 2   rain            48202 non-null  float64
 3   snow            48192 non-null  float64
 4   weather         48155 non-null  object 
 5   date            48204 non-null  object 
 6   Time            48204 non-null  object 
 7   traffic_volume  48204 non-null  int64  
dtypes: float64(3), int64(1), object(4)
memory usage: 2.9+ MB

data.isnull().sum()
     
0
holiday	48143
temp	53
rain	2
snow	12
weather	49
date	0
Time	0
traffic_volume	0

dtype: int64

from typing import Counter
data['temp'].fillna(data['temp'].mean(),inplace=True)
data['rain'].fillna(data['rain'].mean(),inplace=True)
data['snow'].fillna(data['snow'].mean(),inplace=True)


print(Counter(data['weather']))
     
Counter({'Clouds': 15144, 'Clear': 13383, 'Mist': 5942, 'Rain': 5665, 'Snow': 2875, 'Drizzle': 1818, 'Haze': 1359, 'Thunderstorm': 1033, 'Fog': 912, nan: 49, 'Smoke': 20, 'Squall': 4})
/tmp/ipython-input-7-3972614010.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data['temp'].fillna(data['temp'].mean(),inplace=True)
/tmp/ipython-input-7-3972614010.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data['rain'].fillna(data['rain'].mean(),inplace=True)
/tmp/ipython-input-7-3972614010.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data['snow'].fillna(data['snow'].mean(),inplace=True)

data['weather'].fillna('Clouds',inplace=True)
     
/tmp/ipython-input-8-1731991201.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  data['weather'].fillna('Clouds',inplace=True)

corr = data.corr(numeric_only=True)
display(corr)
     
temp	rain	snow	traffic_volume
temp	1.000000	0.009070	-0.019758	0.130034
rain	0.009070	1.000000	-0.000090	0.004714
snow	-0.019758	-0.000090	1.000000	0.000735
traffic_volume	0.130034	0.004714	0.000735	1.000000

import matplotlib.pyplot as plt
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()
     


sns.pairplot(data)
     
<seaborn.axisgrid.PairGrid at 0x7f27a0277fd0>


data.boxplot()
     
<Axes: >


data.head()
     
temp	rain	snow	weather	traffic_volume	day	month	year	hours	minutes	seconds
0	288.28	0.0	0.0	Clouds	5545	02	10	2012	09	00	00
1	289.36	0.0	0.0	Clouds	4516	02	10	2012	10	00	00
2	289.58	0.0	0.0	Clouds	4767	02	10	2012	11	00	00
3	290.13	0.0	0.0	Clouds	5026	02	10	2012	12	00	00
4	291.14	0.0	0.0	Clouds	4918	02	10	2012	13	00	00

y=data['traffic_volume']
x=data.drop(columns=['traffic_volume'],axis=1)
     

categorical = ['weather', 'month', 'day']
numerical = ['temp', 'rain', 'snow', 'year', 'hours', 'minutes', 'seconds']
     

y=data['traffic_volume']
x=data.drop(columns=['traffic_volume'],axis=1)

x=pd.get_dummies(x)

names=x.columns

from sklearn.preprocessing import StandardScaler
scale=StandardScaler()
x=scale.fit_transform(x)
x=pd.DataFrame(x,columns=names)

x.head()
     
temp	rain	snow	weather_Clear	weather_Clouds	weather_Drizzle	weather_Fog	weather_Haze	weather_Mist	weather_Rain	...	hours_16	hours_17	hours_18	hours_19	hours_20	hours_21	hours_22	hours_23	minutes_00	seconds_00
0	0.530485	-0.007463	-0.027235	-0.619949	1.474034	-0.197972	-0.138868	-0.170325	-0.374965	-0.364927	...	-0.207402	-0.204391	-0.207293	-0.205928	-0.206911	-0.207075	-0.207728	-0.210215	0.0	0.0
1	0.611467	-0.007463	-0.027235	-0.619949	1.474034	-0.197972	-0.138868	-0.170325	-0.374965	-0.364927	...	-0.207402	-0.204391	-0.207293	-0.205928	-0.206911	-0.207075	-0.207728	-0.210215	0.0	0.0
2	0.627964	-0.007463	-0.027235	-0.619949	1.474034	-0.197972	-0.138868	-0.170325	-0.374965	-0.364927	...	-0.207402	-0.204391	-0.207293	-0.205928	-0.206911	-0.207075	-0.207728	-0.210215	0.0	0.0
3	0.669205	-0.007463	-0.027235	-0.619949	1.474034	-0.197972	-0.138868	-0.170325	-0.374965	-0.364927	...	-0.207402	-0.204391	-0.207293	-0.205928	-0.206911	-0.207075	-0.207728	-0.210215	0.0	0.0
4	0.744939	-0.007463	-0.027235	-0.619949	1.474034	-0.197972	-0.138868	-0.170325	-0.374965	-0.364927	...	-0.207402	-0.204391	-0.207293	-0.205928	-0.206911	-0.207075	-0.207728	-0.210215	0.0	0.0
5 rows Ã— 90 columns


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)
     

lin_reg=linear_model.LinearRegression()
lin_reg.fit(x_train,y_train)

dtree=tree.DecisionTreeRegressor()
dtree.fit(x_train,y_train)

rand=ensemble.RandomForestRegressor()
rand.fit(x_train,y_train)

svr=svm.SVR()
svr.fit(x_train,y_train)

xgb=xgboost.XGBRegressor()
xgb.fit(x_train,y_train)

     
XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=None,
             num_parallel_tree=None, random_state=None, ...)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

p1 = lin_reg.predict(x_train)
p2 = dtree.predict(x_train)
p3 = rand.predict(x_train)
p4 = svr.predict(x_train)
p5 = xgb.predict(x_train)
     

from sklearn import metrics

print(metrics.r2_score(p1,y_train))
print(metrics.r2_score(p2,y_train))
print(metrics.r2_score(p3,y_train))
print(metrics.r2_score(p4,y_train))
print(metrics.r2_score(p5,y_train))
     
0.7179649343748373
1.0
0.9732380915094122
-128.07484438317314
0.8328073024749756

p1=lin_reg.predict(x_test)
p2=dtree.predict(x_test)
p3=rand.predict(x_test)
p4=svr.predict(x_test)
p5=xgb.predict(x_test)

print(metrics.r2_score(p1,y_test))
print(metrics.r2_score(p2,y_test))
print(metrics.r2_score(p3,y_test))
print(metrics.r2_score(p4,y_test))
print(metrics.r2_score(p5,y_test))
     
0.7252956261893733
0.6954585660284183
0.7919545127631256
-127.08917950780983
0.7835054397583008

MSE=metrics.mean_squared_error(p3,y_test)
np.sqrt(MSE)
     
np.float64(828.7468382375185)

import pickle

pickle.dump(rand,open("model.pkl",'wb'))

     

import pickle
with open("model.pkl", "wb") as f:
    pickle.dump(rand, f)
     

import pickle

with open("scaler.pkl","wb") as f:
  pickle.dump(scale,f)
     

import pickle
with open("columns.pkl", "wb") as f:
    pickle.dump(x.columns.tolist(), f)

     